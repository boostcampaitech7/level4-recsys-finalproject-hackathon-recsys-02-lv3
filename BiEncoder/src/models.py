import os
from itertools import combinations
from pathlib import Path
import pickle
import numpy as np
from tqdm import tqdm
import hashlib
import json
import networkx as nx
import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel


class BERTTextEncoder(nn.Module):
    '''
    Freezeëœ BERT ê¸°ë°˜ì˜ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìˆ˜í–‰í•˜ëŠ” ì¸ì½”ë” í´ë˜ìŠ¤

    Args:
        config (OmegaConf): ëª¨ë¸ ì„¤ì • ì •ë³´
    
    Attributes:
        tokenizer (AutoTokenizer): BERT í† í¬ë‚˜ì´ì €
        bert (AutoModel): ì‚¬ì „ í•™ìŠµëœ BERT ëª¨ë¸
        linear (nn.Linear): ìµœì¢… ì„ë² ë”© ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì„ í˜• ë ˆì´ì–´
    '''
    def __init__(self, config):
        super().__init__()
        self.tokenizer = AutoTokenizer.from_pretrained(config.model.bert_pretrained)
        self.bert = AutoModel.from_pretrained(config.model.bert_pretrained)

        for param in self.bert.parameters():
            param.requires_grad = False

        self.linear = nn.Linear(768, config.model.output_dim)
    
    def forward(self, texts):
        texts = [str(text) for text in texts]
        inputs = self.tokenizer(texts, return_tensors="pt", truncation=True, padding=True)
        inputs = {k: v.to(self.linear.weight.device) for k, v in inputs.items()}
        
        outputs = self.bert(**inputs)
        cls_emb = outputs.last_hidden_state[:, 0, :]
        x = self.linear(cls_emb)
        x = F.relu(x)
        return x


class NumericEncoder(nn.Module):
    '''
    ìˆ«ìí˜• ë°ì´í„°ë¥¼ ì •ê·œí™”í•´ ì²˜ë¦¬í•˜ëŠ” ì¸ì½”ë” í´ë˜ìŠ¤

    Args:
        config (OmegaConf): ëª¨ë¸ ì„¤ì • ì •ë³´
    '''
    def __init__(self, config):
        super().__init__()
        self.linear1 = nn.Linear(2, 64)
        self.linear2 = nn.Linear(64, config.model.output_dim)

    def forward(self, x):
        if len(x.shape) == 1:
            x = x.unsqueeze(0)
        x = F.relu(self.linear1(x))
        x = self.linear2(x)
        return F.relu(x)


class SongEncoder(nn.Module):
    '''
    ê³¡ì˜ ë‹¤ì–‘í•œ ë©”íƒ€ë°ì´í„°ë¥¼ ê²°í•©í•´ ìµœì¢… ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸

    Args:
        config (OmegaConf): ëª¨ë¸ ì„¤ì • ì •ë³´
        playlist_info (dict, optional): í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ê´€ë ¨ ì •ë³´
        cluster_embeds (dict, optional): í´ëŸ¬ìŠ¤í„° ì„ë² ë”© ì •ë³´
        clusters_dict (dict, optional): í´ëŸ¬ìŠ¤í„° ì •ë³´ ë”•ì…”ë„ˆë¦¬
    '''

    def __init__(self, config, playlist_info=None, cluster_embeds=None, clusters_dict=None): 
        super().__init__()
        self.artist_encoder = PlaylistAwareArtistEncoder(playlist_info, output_dim=config.model.mha_embed_dim, cache_dir='./cache')
        self.track_encoder = BERTTextEncoder(config)
        self.playlist_encoder = BERTTextEncoder(config)

        self.genres_encoder = GenreClusterEncoder(clusters_dict, cluster_embeds, config)

        self.numeric_encoder = NumericEncoder(config)

        self.mha = nn.MultiheadAttention(embed_dim=config.model.mha_embed_dim, num_heads=config.model.mha_heads, batch_first=True)
        self.final_fc = nn.Linear(config.model.mha_embed_dim, config.model.final_dim)
        nn.init.xavier_uniform_(self.final_fc.weight)

    def forward(self, artists, tracks, playlists, listeners, lengths, genres):
        '''
        ì…ë ¥ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³¡ ì„ë² ë”© ìƒì„±

        Args:
            artists (List[str]): ì•„í‹°ìŠ¤íŠ¸ ëª©ë¡
            tracks (List[str]): íŠ¸ë™ ì œëª© ëª©ë¡
            playlists (List[str]): í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì œëª© ëª©ë¡
            listeners (torch.Tensor): ì²­ì·¨ì ìˆ˜
            lengths (torch.Tensor): íŠ¸ë™ ê¸¸ì´
            genres (List[List[str]]): ì¥ë¥´ ëª©ë¡

        Returns:
            torch.Tensor: ì •ê·œí™”ëœ ê³¡ ì„ë² ë”©
        '''
            
        artist_emb = self.artist_encoder(artists)
        track_emb = self.track_encoder(tracks)
        playlist_emb = self.playlist_encoder(playlists)
        genres_emb = self.genres_encoder(genres)

        num_tensor = torch.tensor(list(zip(listeners, lengths)), dtype=torch.float32).to(artist_emb.device)
        numeric_emb = self.numeric_encoder(num_tensor)

        # Apply Multi-Head Attention
        features = torch.stack([artist_emb, track_emb, playlist_emb, genres_emb, numeric_emb], dim=1)
        
        attn_output, _ = self.mha(features, features, features)
        agg_vector = attn_output.mean(dim=1)

        final_emb = self.final_fc(agg_vector)

        return F.normalize(final_emb, p=2, dim=1)


class GenreEncoder(nn.Module):
    '''
    ì¥ë¥´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ê·œí™”ëœ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ì¸ì½”ë” 

    Args:
        config (OmegaConf): ëª¨ë¸ ì„¤ì • ì •ë³´
    '''

    def __init__(self, config):
        super().__init__()
        self.tokenizer = AutoTokenizer.from_pretrained(config.model.bert_pretrained)
        self.bert = AutoModel.from_pretrained(config.model.bert_pretrained)
        self.linear = nn.Linear(768, config.model.genre_embed_dim)

        for param in self.bert.parameters():
            param.requires_grad = False

    def forward(self, genres_batch):
        if isinstance(genres_batch[0], list):
            texts = [" ".join(genres) for genres in genres_batch]
        else:
            texts = [str(genres) for genres in genres_batch]

        inputs = self.tokenizer(texts, return_tensors="pt", truncation=True, padding=True)
        inputs = {k: v.to(self.linear.weight.device) for k, v in inputs.items()}
        
        outputs = self.bert(**inputs)
        cls_emb = outputs.last_hidden_state[:, 0, :]

        x = self.linear(cls_emb)
        x = F.relu(x)
        return F.normalize(x, p=2, dim=1)


# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["TOKENIZERS_PARALLELISM"] = "false"

class PlaylistAwareArtistEncoder(nn.Module):
    '''
    í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì•„í‹°ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ëª¨ë¸

    Args:
        playlist_info (dict): í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì™€ ì•„í‹°ìŠ¤íŠ¸ ë§¤í•‘ ì •ë³´
        output_dim (int, optional): ì¶œë ¥ ì„ë² ë”© ì°¨ì›
        cache_dir (str, optional): ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    '''
    def __init__(self, playlist_info, output_dim=64, cache_dir='./cache'):
        super().__init__()
        self.output_dim = output_dim
        self.artist2id = {}  # Mapping from artist name to ID
        self.id2artist = {}  # Mapping from ID to artist name
        self.playlist_info = playlist_info
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸš€ Using device: {self.device}")
        
        # Generate graphh
        self.graph = self.get_or_create_graph()
        
        # Dynamic artist registration
        unique_artists = list(self.graph.nodes())
        self.artist2id = {artist: idx for idx, artist in enumerate(unique_artists)}
        self.id2artist = {idx: artist for artist, idx in self.artist2id.items()}
        
        # Initialize embedding layer on GPU
        self.embedding = nn.Embedding(len(unique_artists) + 100, output_dim).to(self.device)
        self.init_embeddings_with_graph_info()

    def get_cache_key(self):
        '''
        í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ë¥¼ ìœ„í•œ MD5 hashê³ ìœ  ìºì‹œ í‚¤ ìƒì„±
        
        '''
        playlist_str = json.dumps(self.playlist_info, sort_keys=True)
        return hashlib.md5(playlist_str.encode()).hexdigest()

    def get_or_create_graph(self):
        '''
        ìºì‹±ëœ ê·¸ë˜í”„ ë¡œë“œ(ì—†ë‹¤ë©´ ìƒì„±)
        
        '''
        cache_key = self.get_cache_key()
        cache_file = self.cache_dir / f"graph_{cache_key}.pkl"
        
        if cache_file.exists():
            print("ğŸ”„ Loading cached graph...")
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        
        print("ğŸ†• Creating new graph...")
        graph = self.create_artist_graph_advanced()
        
        with open(cache_file, 'wb') as f:
            pickle.dump(graph, f)
        
        return graph

    def create_artist_graph_advanced(self):
        """
        í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì•„í‹°ìŠ¤íŠ¸ ê°„ ê·¸ë˜í”„ ìƒì„±

        Returns:
            networkx.Graph: ì•„í‹°ìŠ¤íŠ¸ ê°„ì˜ ê·¸ë˜í”„
        """
        print("ğŸ” Starting graph creation...")
        edge_weights = {}
        
        # Process playlists
        items = list(self.playlist_info.items())
        for playlist_name, artists in tqdm(items, desc="Processing playlists"):
            if not playlist_name.strip() or len(artists) < 2:
                continue
                
            cleaned_artists = [artist.strip() for artist in artists if artist and artist.strip()]
            if len(cleaned_artists) < 2:
                continue
                
            for artist1, artist2 in combinations(cleaned_artists, 2):
                edge = tuple(sorted([artist1, artist2]))
                edge_weights[edge] = edge_weights.get(edge, 0) + 1

        # Construct graph
        G = nx.Graph()
        G.add_weighted_edges_from(
            (artist1, artist2, weight)
            for (artist1, artist2), weight in edge_weights.items()
        )
        
        # Apply weight-based filtering
        weights = [d['weight'] for (u, v, d) in G.edges(data=True)]
        weight_threshold = np.percentile(weights, 10)
        edges_to_remove = [(u, v) for (u, v, d) in G.edges(data=True) 
                          if d['weight'] < weight_threshold]
        G.remove_edges_from(edges_to_remove)
        
        print(f"ğŸ” Graph completed with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges")
        return G

    def init_embeddings_with_graph_info(self):
        '''
        ê·¸ë˜í”„ì˜ ì£¼ìš” ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì°¾ì•„ ì„ë² ë”©ì„ ì´ˆê¸°í™”
        '''
        print("ğŸ“Š Initializing embeddings...")
        pagerank = nx.pagerank(self.graph)
        degree_cent = nx.degree_centrality(self.graph)
        
        # Allocate tensor for embeddings
        embedding_weights = torch.zeros(self.embedding.weight.shape, device=self.device)
        
        for artist, idx in tqdm(self.artist2id.items(), desc="Initializing embeddings"):
            centrality = (pagerank.get(artist, 0.5) + degree_cent.get(artist, 0.5)) / 2
            std = np.sqrt(2.0 / (self.graph.number_of_nodes() + self.output_dim))
            embedding_weights[idx] = torch.randn(self.output_dim, device=self.device) * std * centrality
        
        self.embedding.weight.data.copy_(embedding_weights)

    @torch.no_grad()
    def forward(self, artists_batch):
        """
        ì…ë ¥ëœ ì•„í‹°ìŠ¤íŠ¸ ë°°ì¹˜ì— ëŒ€í•œ ì„ë² ë”© ë°˜í™˜

        Args:
            artists_batch (List[List[str]]): íŠ¸ë™ë³„ ì•„í‹°ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸

        Returns:
            torch.Tensor: ì•„í‹°ìŠ¤íŠ¸ ì„ë² ë”© ë²¡í„°
        """
        all_artists = set()
        for track_artists in artists_batch:
            all_artists.update(track_artists)
        
        # Register new artists dynamically
        for artist in all_artists:
            self.register_new_artist(artist)
        
        # Compute batch embeddings on GPU
        batch_embeddings = []
        for track_artists in artists_batch:
            artist_indices = torch.tensor([self.artist2id[artist] for artist in track_artists], 
                                        device=self.device)
            track_embeddings = self.embedding(artist_indices)
            batch_embeddings.append(torch.mean(track_embeddings, dim=0))
        
        return torch.stack(batch_embeddings)

    def register_new_artist(self, artist):
        '''
        ë™ì ìœ¼ë¡œ ìƒˆë¡œìš´ ì•„í‹°ìŠ¤íŠ¸ ì¶”ê°€ 
        
        '''
        if artist not in self.artist2id:
            with torch.no_grad():
                new_id = len(self.artist2id)
                self.artist2id[artist] = new_id
                self.id2artist[new_id] = artist
                
                # Expand embedding matrix if needed
                if new_id >= self.embedding.num_embeddings:
                    new_embedding = nn.Embedding(new_id + 100, self.output_dim).to(self.device)
                    new_embedding.weight.data[:self.embedding.num_embeddings] = self.embedding.weight.data
                    
                    # Initialize new embeddings
                    std = np.sqrt(2.0 / (self.graph.number_of_nodes() + self.output_dim))
                    new_embedding.weight.data[self.embedding.num_embeddings:] = \
                        torch.randn(new_embedding.num_embeddings - self.embedding.num_embeddings, 
                                  self.output_dim, device=self.device) * std
                    
                    self.embedding = new_embedding

    def to(self, device):
        """
        ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        """
        self.device = device
        self.embedding = self.embedding.to(device)
        return super().to(device)


class DistilBertTextEncoder(torch.nn.Module):
    '''
    DistilBERT ê¸°ë°˜ì˜ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìˆ˜í–‰í•˜ëŠ” ì¸ì½”ë” í´ë˜ìŠ¤

    Args:
        pretrained_name (str, optional): ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ì´ë¦„
        output_dim (int, optional): ì¶œë ¥ ì„ë² ë”© ì°¨ì›

    Attributes:
        tokenizer (AutoTokenizer): BERT í† í¬ë‚˜ì´ì €
        bert (AutoModel): ì‚¬ì „ í•™ìŠµëœ DistilBERT ëª¨ë¸
        linear (nn.Linear): BERT ì¶œë ¥ì„ output_dim í¬ê¸°ë¡œ ë³€í™˜í•˜ëŠ” ì„ í˜• ë ˆì´ì–´
    '''

    def __init__(self, pretrained_name="distilbert-base-uncased", output_dim=64):
        super().__init__()
        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_name)
        self.bert = AutoModel.from_pretrained(pretrained_name)

        for param in self.bert.parameters():
            param.requires_grad = False

        self.linear = torch.nn.Linear(768, output_dim)
    
    def forward(self, texts):
        '''
        ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ DistilBERTë¥¼ í†µí•´ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜.
        
        '''

        inputs = self.tokenizer(texts, return_tensors="pt", truncation=True, padding=True)
        inputs = {k: v for k, v in inputs.items()}

        outputs = self.bert(**inputs)
        cls_emb = outputs.last_hidden_state[:, 0, :] 
        x = self.linear(cls_emb) 
        x = F.relu(x)
        return x


class GenreClusterEncoder(nn.Module):
    '''
    ì¥ë¥´ í´ëŸ¬ìŠ¤í„° ì •ë³´ë¥¼ í™œìš©í•œ ì¥ë¥´ ì„ë² ë”© ì¸ì½”ë”

    Args:
        clusters_dict (dict): ì¥ë¥´ í´ëŸ¬ìŠ¤í„° ì •ë³´ ë”•ì…”ë„ˆë¦¬
        cluster_embeds (dict): í´ëŸ¬ìŠ¤í„°ë³„ ì‚¬ì „ í•™ìŠµëœ ì„ë² ë”©
        config (OmegaConf): ëª¨ë¸ ì„¤ì • ì •ë³´

    Attributes:
        clusters_dict (dict): í´ëŸ¬ìŠ¤í„°ë³„ ì¥ë¥´ ë§¤í•‘
        cluster_embeds (dict): í´ëŸ¬ìŠ¤í„°ë³„ ì„ë² ë”© ë²¡í„°
        tokenizer (AutoTokenizer): BERT í† í¬ë‚˜ì´ì €
        bert (AutoModel): ì‚¬ì „ í•™ìŠµëœ BERT ëª¨ë¸
        linear (nn.Linear): ì¥ë¥´ ì„ë² ë”©ì„ ë³€í™˜í•˜ëŠ” ì„ í˜• ë ˆì´ì–´
    '''
    def __init__(self, clusters_dict, cluster_embeds, config):

        super().__init__()
        self.clusters_dict = clusters_dict
        self.cluster_embeds = {cid: emb.clone().detach() for cid, emb in cluster_embeds.items()}  # No grad
        self.tokenizer = AutoTokenizer.from_pretrained(config.model.bert_pretrained)
        self.bert = AutoModel.from_pretrained(config.model.bert_pretrained)

        for param in self.bert.parameters():
            param.requires_grad = False

        self.linear = nn.Linear(768, config.model.output_dim) 

    def infer_cluster_for_genres(self, genres, device):
        '''        
        ì…ë ¥ëœ ì¥ë¥´ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ì„ë² ë”© ìƒì„±
        
        '''

        known_cluster_embs = []
        unknown_genres = []

        # Check if genres belong to existing clusters
        for g in genres:
            found = False
            for cid, glist in self.clusters_dict.items():
                if g in glist:
                    known_cluster_embs.append(self.cluster_embeds[cid].to(device))
                    found = True
                    break
            if not found:
                unknown_genres.append(g)

        # Handle unknown genres using BERT
        if unknown_genres:
            inputs = self.tokenizer(unknown_genres, return_tensors="pt", truncation=True, padding=True)
            inputs = {k: v.to(device) for k, v in inputs.items()}
            with torch.no_grad():
                outputs = self.bert(**inputs)
            texts_emb = outputs.last_hidden_state[:, 0, :] 
            unknown_emb = self.linear(texts_emb).mean(dim=0) 
            known_cluster_embs.append(F.relu(unknown_emb))

        # Return zero vector if no known embeddings exist
        if len(known_cluster_embs) == 0:
            return torch.zeros(self.linear.out_features, device=device)
        else:
            return torch.stack(known_cluster_embs, dim=0).mean(dim=0)

    def forward(self, genres_batch):
        '''
        ì¥ë¥´ ë°°ì¹˜ ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ ì„ë² ë”© ë²¡í„°ë¥¼ ë°˜í™˜
        '''
        device = next(self.parameters()).device
        batch_embeddings = [self.infer_cluster_for_genres(genres, device) for genres in genres_batch]
        return torch.stack(batch_embeddings, dim=0)
